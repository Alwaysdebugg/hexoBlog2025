---
title: 本地部署DeepSeek大模型
date: 2025-02-09 10:00:00
image: img/ollama.png
tags: [AI, 本地部署]
---

### 本地部署大模型需要用到的工具
- macbook pro
- ollama ---运行大模型
- supabase --- 管理本地聊天数据
- docker
- chatbot --- 对话框ui

### 第一步：ollama下载 & pull model
官网：[https://ollama.com/]

![ollama](img/ollama.png)

**选择大模型**
以我为例，我选择的deepseek-r1:7b, 安装完ollama之后，
在Terminal中运行：
`ollama run deepseek-r1:7b`

![pull](img/pull.png)
这就说明目标模型已经可以在本地运行了。

### 第二步：**Chatbot UI**
当大模型有了，下一步就是找一个可以用来进行对话的 “壳”了，不用chatbot对话框当然也是可以的，只是需要在command line中对话了。

**chatbot-ui** ： https://github.com/mckaywrigley/chatbot-ui.git
*这里需要了解如何从github clone项目到本地，需要用到 `git clone`，看项目README*

当将这个项目拉取到本地之后，用vscode（任何 IDE）打开项目；
安装docker（不能忘记）；
安装完之后在vscode中命令行运行以下命令：

- `npm install` --- 安装chatbot依赖
- `brew install supabase/tap/supabase` --- 安装supabase(mac先安装Homebrew)
- `supabase start` ---启动
- `cp .env.local.example .env.local` --- supabase配置信息
- `supabase status` 获取supabase状态

运行后，会显示 **Supabase 的 API URL 和密钥**，你需要把这些值填入 `.env.local`；

- `API URL:` 对应 `NEXT_PUBLIC_SUPABASE_URL`
- `anon key:` 对应  `NEXT_PUBLIC_SUPABASE_ANON_KEY`
- `service_role key:` 对应 `SUPABASE_SERVICE_ROLE_KEY`

SQL 设置：
- 找到chatbot项目文件中`supabase/migrations/20240108234540_setup.sql` ;
- 在这个文件中需要修改两个值：
	- `project_url` (line 53): 一般情况下，默认就可以；
	- `service_role_key` (line 54): 对应上述 `SUPABASE_SERVICE_ROLE_KEY`；


### 第三步：**运行Chatbot项目**

在vscode中的 `terminal` 运行如下command：
- `npm run chat`

如果之前的配置都没问题的话，项目会被成功跑起来；
界面如下：

![chatbot](img/ui.png)

创建一个账户，并登陆；
进入界面后右上角选择model，选择本地运行的deepseek-r1;
现在你就可以和你的本地大模型对话了。





